{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4llCSdu6hXX",
        "outputId": "7d98eeba-1f6e-4e00-8fc7-7af7b2824ffb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/802.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/802.4 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/802.4 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m798.7/802.4 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.4/802.4 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.1/211.1 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.7/228.7 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.7/97.7 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for tinysegmenter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for feedfinder2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for jieba3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain newspaper3k -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "from langchain_community.document_loaders import NewsURLLoader\n",
        "\n",
        "urls = [\n",
        "    \"https://www.livemint.com/news/india/ayodhya-ram-temple-govt-offices-to-observe-half-day-on-january-22-check-timing-and-other-details-11705570875108.html\"\n",
        "]\n",
        "\n",
        "loader = NewsURLLoader(urls=urls)\n",
        "data = loader.load()\n",
        "hi = data[0].page_content\n",
        "\n",
        "url = \"https://frhfgqfhpbryv7-5000.proxy.runpod.net/v1/completions\"\n",
        "\n",
        "prompts = f\"\"\"\n",
        "                 <|system|>\n",
        "                       {hi}</s>\n",
        "                 <|user|>\n",
        "                        1.tell the summary of the above context in 100 words. tell with appropriate hashtags.tell with emojis.\n",
        "                        2.Give three type of opinions(in one line) about the context with emojis:- 1.positive 2.neutral 3.negative.\n",
        "                        3. tell the news category it belongs to.\n",
        "                        4.detect appropriate sentiments:\n",
        "                           1. Positive (Uplifting/Optimistic)\n",
        "                           2. Outrage (Outrage-Inducing)\n",
        "                           3. Info (Informative)\n",
        "                           4. Debate (Controversial)\n",
        "                           5. Sad (Sorrowful)\n",
        "                           6. Alert (Fearful)\n",
        "                           7. LOL (Amusing)\n",
        "                           8. Retro (Nostalgic)\n",
        "                           9. Insight (Analytical)\n",
        "                           10.Balanced (Neutral)\n",
        "                           11.Negative (Pessimistic)\n",
        "                        5.tell the language of the context.\n",
        "                        6.tell the country and place news belongs to.\n",
        "                        7.Main persons in the news: </s>\n",
        "                 <|assistant|>\n",
        "                \"\"\"\n",
        "\n",
        "data = {\n",
        "    \"prompt\": prompts,\n",
        "    \"max_tokens\": 500,\n",
        "    \"temperature\": 0.5,\n",
        "    \"top_p\": 0.9,\n",
        "    \"guidance_scale\" : 1,\n",
        "    \"repetition_penalty\" : 1.15,\n",
        "    \"top_k\": 15\n",
        "}\n",
        "headers = {\n",
        "    'Content-Type': 'application/json'\n",
        "}\n",
        "\n",
        "# Making the POST request\n",
        "response = requests.post(url, headers=headers, json=data, verify=False)\n",
        "\n",
        "# Check if response is successful\n",
        "if response.status_code == 200:\n",
        "    try:\n",
        "        # Extracting the specific part of the JSON response\n",
        "        assistant_message = response.json()['choices'][0]['text']\n",
        "        print(assistant_message)\n",
        "    except KeyError as e:\n",
        "        print(f\"Key error: {e}\")\n",
        "    except IndexError as e:\n",
        "        print(f\"Index error: {e}\")\n",
        "else:\n",
        "    print(f\"Failed to get a successful response. Status code: {response.status_code}\")"
      ],
      "metadata": {
        "id": "h7t7VUt86lVH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}